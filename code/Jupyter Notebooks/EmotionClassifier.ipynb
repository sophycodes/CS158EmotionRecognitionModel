{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad43b2-f485-4ca8-9d70-e7193934f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398525b-c0a9-4b53-99c5-88907b198e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b486a9-a636-4ed4-9a56-900dc329d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "base_dir = 'path/to/facial-emotion-recognition-dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Image transformations\n",
    "img_size = 48\n",
    "batch_size = 32\n",
    "\n",
    "# Apply simple transformations to ensure consistent input\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure grayscale\n",
    "    transforms.Resize((48, 48)),                   # Ensure size 48x48\n",
    "    transforms.ToTensor(),                         # Convert to tensor [0,1]\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])    # Normalize to [-1,1] keeps numbers small and centered around zero to make traininf faster\n",
    "])\n",
    "\n",
    "# Do the same transformations for test\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# loading, labeling, batching, and shuffling images\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "# 1. Scan all subfolders in data\n",
    "# 2. Each subfolder becomes a class (angry=0, happy=1, sad=2, etc.)\n",
    "# 3. Loads all images from each subfolder\n",
    "# 4. Applies the transform to each image\n",
    "# 5. Creates (image, label) pairs\n",
    "\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "# FOR INITIAL TESTING: Using only 10 images per emotion\n",
    "# 7 emotions Ã— 10 images = 70 total training images\n",
    "# (Will scale up to full dataset on HPC later)\n",
    "\n",
    "# Split training data for validation (80-20 split)\n",
    "train_size = int(0.8 * len(train_dataset))  # 80% for training (56 images)\n",
    "val_size = len(train_dataset) - train_size  # 20% for validation (14 images)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,        # The dataset to load from\n",
    "    batch_size=32,        # Load 32 images at a time \n",
    "    shuffle=True          # Randomize order each epoch, to prevent model from memorizing order\n",
    ")\n",
    "\n",
    "# validation loader - for checking model performance during training\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,          # 14 validation images (2 per emotion on average)\n",
    "    batch_size=batch_size, # Process 32 at a time (will only have 1 batch of 14)\n",
    "    shuffle=False         # - Makes validation scores comparable epoch-to-epoch\n",
    ")\n",
    "\n",
    "# Test loader - for final evaluation AFTER training is complete\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,         # Completely separate test images\n",
    "    batch_size=32,        # Process in batches of 32\n",
    "    shuffle=False         # Keep test order consistent (for reproducibility),  Same order every run = same final score                  \n",
    ")\n",
    "\n",
    "# Print dataset info for verification\n",
    "print(\"=\"*50)\n",
    "print(\"DATASET SIZES (Initial Small Version):\")\n",
    "print(f\"Training images: {len(train_dataset)} ({len(train_dataset)//7} per emotion)\")\n",
    "print(f\"Validation images: {len(val_dataset)} ({len(val_dataset)//7} per emotion)\")\n",
    "print(f\"Test images: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {len(train_dataset.dataset.classes)}\")\n",
    "print(f\"Classes: {train_dataset.dataset.classes}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Batches per epoch - Train: {len(train_loader)}\")\n",
    "print(f\"Batches per epoch - Val: {len(val_loader)}\")\n",
    "print(f\"Batches per epoch - Test: {len(test_loader)}\")\n",
    "print(\"=\"*50)\n",
    "print(\"NOTE: This is a small subset for initial testing.\")\n",
    "print(\"Full dataset will be used when running on HPC.\")\n",
    "\n",
    "\n",
    "# Get class names\n",
    "class_names = train_dataset.dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "\n",
    "def check_data_loaded_correctly(data_loader):\n",
    "    \"\"\"Function to make sure images are loading properly\"\"\"\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    print(f\"Batch shape: {images.shape}\")  # Should be [32, 1, 48, 48]\n",
    "    print(f\"Labels shape: {labels.shape}\")  # Should be [32]\n",
    "    \n",
    "    # Show a few images\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Denormalize for display\n",
    "    images_display = images * 0.5 + 0.5\n",
    "    \n",
    "    emotion_names = train_dataset.classes\n",
    "    \n",
    "    for i in range(8):\n",
    "        img = images_display[i].squeeze()\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f\"{emotion_names[labels[i]]}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "check_data_loaded_correctly(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
