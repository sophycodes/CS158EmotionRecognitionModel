{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096238dc-010c-46b8-a5fc-56e03986e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SmallPredictor.py\n",
    "Use the small CNN (trained on 10 images per emotion) to predict emotion from a single input image\n",
    "Run python SmallPredictor.py path/to/image.jpg\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca08c0e2-f589-4757-9244-7308c971d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "\n",
    "img_size = 48  # model expects 48x48 grayscale images\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device:\", device)\n",
    "\n",
    "# same class ordering used during training\n",
    "class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66041669-bcfc-4987-85ad-309cff42c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model (same as SmallDataTrainer.py)\n",
    "\n",
    "class small_cnn(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 12 * 12, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "# load model\n",
    "\n",
    "model_path = \"small_emotion_cnn.pth\"  # saved model file\n",
    "\n",
    "if not os.path.exists(model_path):  # check if file exists\n",
    "    print(f\"ERROR: model file not found: {model_path}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# create the model and load learned weights\n",
    "model = small_cnn(num_classes=len(class_names)).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()  # set model to evaluation mode\n",
    "\n",
    "print(\"loaded model:\", model_path)\n",
    "\n",
    "\n",
    "# image transform (same as training)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # convert to grayscale\n",
    "    transforms.Resize((img_size, img_size)),  # resize to 48Ã—48\n",
    "    transforms.ToTensor(),  # convert to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # normalize to [-1,1]\n",
    "])\n",
    "\n",
    "\n",
    "# predict function (load image, preprocess it, run model, and overlay prediction)\n",
    "\n",
    "def predict_emotion(image_path):  # ensure file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # load original image with OpenCV (for display + drawing text)\n",
    "    original = cv2.imread(image_path)\n",
    "    if original is None:\n",
    "        print(\"ERROR: Could not read image with cv2.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # also load image via PIL for preprocessing\n",
    "    pil_img = Image.open(image_path).convert(\"RGB\")  # ensure RGB format\n",
    "\n",
    "    # apply same preprocessing as training\n",
    "    tensor = transform(pil_img)\n",
    "    tensor = tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # prediction step (no gradient needed)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tensor)\n",
    "        pred_label = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "    emotion = class_names[pred_label]\n",
    "    print(f\"Predicted emotion: {emotion}\")\n",
    "\n",
    "\n",
    "    # draw prediction text on original image\n",
    "    \n",
    "    # make editable copy\n",
    "    output_img = original.copy()\n",
    "\n",
    "    # height, width\n",
    "    h, w = output_img.shape[:2]\n",
    "\n",
    "    # text position near top-left\n",
    "    text_pos = (10, int(h * 0.1))\n",
    "\n",
    "    # auto-scale text size based on image resolution\n",
    "    font_scale = max(0.6, min(w, h) / 300)\n",
    "\n",
    "    # draw text label\n",
    "    cv2.putText(\n",
    "        output_img,\n",
    "        emotion,\n",
    "        text_pos,\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        font_scale,  # automatically scaled font size\n",
    "        (0, 255, 0),  # green text\n",
    "        2,  # text thickness\n",
    "        cv2.LINE_AA\n",
    "    )\n",
    "\n",
    "    # save result\n",
    "    save_path = \"predicted_output.jpg\"\n",
    "    cv2.imwrite(save_path, output_img)\n",
    "    print(f\"Saved output image as {save_path}\")\n",
    "\n",
    "    # show\n",
    "    cv2.imshow(\"prediction\", output_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# main to handle command-line arguments\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2:  # require image path\n",
    "        print(\"Usage: python SmallPredictor.py <image_path>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    img_path = sys.argv[1]  # read image from CLI\n",
    "    predict_emotion(img_path)  # run prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
